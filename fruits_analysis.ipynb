{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_path = os.path.abspath(\"fruits-360/Training\")\n",
    "test_path = os.path.abspath(\"fruits-360/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls fruits-360/Training | wc -l # the amount of files in the folder\n",
    "a = !ls fruits-360/Training\n",
    "print(a[0])\n",
    "print(a[130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "# check the amount of files in the folder. if there is only 100 files in the folder, skip it\n",
    "# so all folders will have 100 pics in them.\n",
    "\n",
    "# maybe you can write a function later for practice that removes files till there's a select\n",
    "# amount of files\n",
    "# cause right now i have like 35 images in every folder, which might not be enough for training\n",
    "\n",
    "# like a while loop that checks all folders. and while at least one of the folders has\n",
    "# more than 100 images in it, the whole code runs\n",
    "\n",
    "def reduce_folder_size_by_increment(files, path, allowed_min, incr):\n",
    "    i = 0\n",
    "    for fruit in files:\n",
    "        if len(os.listdir(os.path.join(path,fruit)))- incr < allowed_min:\n",
    "                continue\n",
    "        for photo in sample(os.listdir(os.path.join(path,fruit)), incr):\n",
    "            if os.path.exists(os.path.join(path,fruit)):\n",
    "                os.remove(path+\"/\"+fruit+\"/\"+photo)\n",
    "                i+= 1\n",
    "            else:\n",
    "                i+= 1\n",
    "    print(f\"{i} photos were removed in this function run.\")\n",
    "files = os.listdir(train_path)\n",
    "files.remove(\".DS_Store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 photos were removed in this function run.\n"
     ]
    }
   ],
   "source": [
    "# this lists every single folder\n",
    "# .ds_store is some weird internal folder\n",
    "reduce_folder_size_by_increment(files, train_path, 100, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 photos were removed in this function run.\n"
     ]
    }
   ],
   "source": [
    "reduce_folder_size_by_increment(files, test_path, 100, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato 4 160\n",
      "Apple Red Delicious 166\n",
      "Tomato 3 146\n",
      "Huckleberry 166\n",
      "Blueberry 154\n",
      "Pear Red 122\n",
      "Banana Lady Finger 152\n",
      "Melon Piel de Sapo 146\n",
      "Pear 164\n",
      "Cherry 1 164\n",
      "Strawberry 164\n",
      "Nut Forest 118\n",
      "Avocado 143\n",
      "Tomato 2 125\n",
      "Pomegranate 164\n",
      "Dates 166\n",
      "Carambula 166\n",
      "Potato Red Washed 151\n",
      "Granadilla 166\n",
      "Kohlrabi 157\n",
      "Tamarillo 166\n",
      "Pepper Red 122\n",
      "Fig 134\n",
      "Ginger Root 99\n",
      "Kiwi 156\n",
      "Cherry Wax Yellow 164\n",
      "Lemon 164\n",
      "Guava 166\n",
      "Apple Golden 2 164\n",
      "Pear Stone 137\n",
      "Apple Red 1 164\n",
      "Cauliflower 134\n",
      "Mandarine 166\n",
      "Quince 166\n",
      "Strawberry Wedge 146\n",
      "Pear Monster 166\n",
      "Raspberry 166\n",
      "Pitahaya Red 166\n",
      "Nut Pecan 178\n",
      "Apple Golden 3 161\n",
      "Redcurrant 164\n",
      "Apple Red Yellow 1 164\n",
      "Pepper Yellow 122\n",
      "Grape Pink 164\n",
      "Banana Red 166\n",
      "Cucumber Ripe 2 156\n",
      "Physalis 164\n",
      "Cherry Rainier 146\n",
      "Maracuja 166\n",
      "Chestnut 153\n",
      "Plum 151\n",
      "Potato Sweet 150\n",
      "Cucumber Ripe 130\n",
      "Hazelnut 157\n",
      "Nectarine 164\n",
      "Cherry Wax Black 164\n",
      "Cantaloupe 2 164\n",
      "Lychee 166\n",
      "Pepper Orange 134\n",
      "Clementine 166\n",
      "Watermelon 157\n",
      "Pear Kaiser 102\n",
      "Mangostan 102\n",
      "Cherry 2 146\n",
      "Pineapple Mini 163\n",
      "Rambutan 164\n",
      "Grape White 166\n",
      "Tomato Yellow 153\n",
      "Apple Braeburn 164\n",
      "Tomato Maroon 127\n",
      "Onion White 146\n",
      "Onion Red Peeled 155\n",
      "Mango 166\n",
      "Potato White 150\n",
      "Apple Crimson Snow 148\n",
      "Potato Red 150\n",
      "Corn Husk 154\n",
      "Cocos 166\n",
      "Mulberry 164\n",
      "Avocado ripe 166\n",
      "Tomato 1 146\n",
      "Passion Fruit 166\n",
      "Apple Granny Smith 164\n",
      "Beetroot 150\n",
      "Kumquats 166\n",
      "Grape White 2 166\n",
      "Apricot 164\n",
      "Eggplant 156\n",
      "Limes 166\n",
      "Corn 150\n",
      "Grape White 4 158\n",
      "Grape White 3 164\n",
      "Tomato Heart 128\n",
      "Apple Pink Lady 152\n",
      "Plum 3 104\n",
      "Pear Williams 166\n",
      "Tomato not Ripened 158\n",
      "Peach 2 146\n",
      "Pomelo Sweetie 153\n",
      "Salak 162\n",
      "Grapefruit Pink 166\n",
      "Apple Golden 1 160\n",
      "Banana 166\n",
      "Apple Red 2 164\n",
      "Onion Red 150\n",
      "Physalis with Husk 164\n",
      "Apple Red Yellow 2 119\n",
      "Grape Blue 128\n",
      "Lemon Meyer 166\n",
      "Plum 2 142\n",
      "Pepino 166\n",
      "Tangelo 166\n",
      "Cactus fruit 166\n",
      "Papaya 164\n",
      "Apple Red 3 144\n",
      "Walnut 149\n",
      "Pear Abate 166\n",
      "Pear 2 132\n",
      "Pear Forelle 134\n",
      "Pineapple 166\n",
      "Tomato Cherry Red 164\n",
      "Cherry Wax Red 164\n",
      "Mango Red 142\n",
      "Orange 160\n",
      "Nectarine Flat 160\n",
      "Kaki 166\n",
      "Pepper Green 148\n",
      "Grapefruit White 164\n",
      "Peach 164\n",
      "Cantaloupe 1 164\n",
      "Peach Flat 164\n"
     ]
    }
   ],
   "source": [
    "mn = 20\n",
    "folders = ([name for name in os.listdir(test_path)\n",
    "            if os.path.isdir(os.path.join(test_path, name))]) # get all directories \n",
    "for folder in folders:\n",
    "    contents = os.listdir(os.path.join(test_path,folder)) # get list of contents\n",
    "    if len(contents) > mn: # if greater than the limit, print folder and number of contents\n",
    "        print(folder,len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato 4 148\n",
      "Apple Red Delicious 160\n",
      "Tomato 3 108\n",
      "Huckleberry 160\n",
      "Blueberry 132\n",
      "Pear Red 136\n",
      "Banana Lady Finger 120\n",
      "Melon Piel de Sapo 108\n",
      "Pear 162\n",
      "Cherry 1 162\n",
      "Strawberry 162\n",
      "Nut Forest 124\n",
      "Avocado 197\n",
      "Tomato 2 142\n",
      "Pomegranate 162\n",
      "Dates 160\n",
      "Carambula 160\n",
      "Potato Red Washed 123\n",
      "Granadilla 190\n",
      "Kohlrabi 171\n",
      "Tamarillo 190\n",
      "Pepper Red 166\n",
      "Fig 102\n",
      "Ginger Root 197\n",
      "Kiwi 166\n",
      "Cherry Wax Yellow 192\n",
      "Lemon 192\n",
      "Guava 190\n",
      "Apple Golden 2 192\n",
      "Pear Stone 111\n",
      "Apple Red 1 192\n",
      "Cauliflower 102\n",
      "Mandarine 190\n",
      "Quince 190\n",
      "Strawberry Wedge 138\n",
      "Pear Monster 190\n",
      "Raspberry 190\n",
      "Pitahaya Red 190\n",
      "Nut Pecan 134\n",
      "Apple Golden 3 181\n",
      "Redcurrant 192\n",
      "Apple Red Yellow 1 192\n",
      "Pepper Yellow 166\n",
      "Grape Pink 192\n",
      "Banana Red 190\n",
      "Cucumber Ripe 2 168\n",
      "Physalis 192\n",
      "Cherry Rainier 138\n",
      "Maracuja 190\n",
      "Chestnut 150\n",
      "Plum 147\n",
      "Potato Sweet 150\n",
      "Cucumber Ripe 192\n",
      "Hazelnut 164\n",
      "Nectarine 192\n",
      "Cherry Wax Black 192\n",
      "Cantaloupe 2 192\n",
      "Lychee 190\n",
      "Pepper Orange 102\n",
      "Clementine 190\n",
      "Watermelon 175\n",
      "Pear Kaiser 100\n",
      "Mangostan 100\n",
      "Cherry 2 138\n",
      "Pineapple Mini 193\n",
      "Rambutan 192\n",
      "Grape White 190\n",
      "Tomato Yellow 159\n",
      "Apple Braeburn 193\n",
      "Tomato Maroon 167\n",
      "Onion White 138\n",
      "Onion Red Peeled 145\n",
      "Mango 190\n",
      "Potato White 150\n",
      "Apple Crimson Snow 144\n",
      "Potato Red 150\n",
      "Corn Husk 162\n",
      "Cocos 190\n",
      "Mulberry 192\n",
      "Avocado ripe 191\n",
      "Tomato 1 138\n",
      "Passion Fruit 190\n",
      "Apple Granny Smith 192\n",
      "Beetroot 150\n",
      "Kumquats 190\n",
      "Grape White 2 190\n",
      "Apricot 192\n",
      "Eggplant 168\n",
      "Limes 190\n",
      "Corn 150\n",
      "Grape White 4 171\n",
      "Grape White 3 192\n",
      "Tomato Heart 184\n",
      "Apple Pink Lady 156\n",
      "Plum 3 100\n",
      "Pear Williams 190\n",
      "Tomato not Ripened 174\n",
      "Peach 2 138\n",
      "Pomelo Sweetie 150\n",
      "Salak 190\n",
      "Grapefruit Pink 190\n",
      "Apple Golden 1 180\n",
      "Banana 190\n",
      "Apple Red 2 192\n",
      "Onion Red 150\n",
      "Physalis with Husk 192\n",
      "Apple Red Yellow 2 172\n",
      "Grape Blue 184\n",
      "Lemon Meyer 190\n",
      "Plum 2 120\n",
      "Pepino 190\n",
      "Tangelo 190\n",
      "Cactus fruit 190\n",
      "Papaya 192\n",
      "Apple Red 3 129\n",
      "Walnut 135\n",
      "Pear Abate 190\n",
      "Pear 2 196\n",
      "Pear Forelle 102\n",
      "Pineapple 190\n",
      "Tomato Cherry Red 192\n",
      "Cherry Wax Red 192\n",
      "Mango Red 126\n",
      "Orange 179\n",
      "Nectarine Flat 180\n",
      "Kaki 190\n",
      "Pepper Green 144\n",
      "Grapefruit White 192\n",
      "Peach 192\n",
      "Cantaloupe 1 192\n",
      "Peach Flat 192\n"
     ]
    }
   ],
   "source": [
    "mn = 20\n",
    "folders = ([name for name in os.listdir(train_path)\n",
    "            if os.path.isdir(os.path.join(train_path, name))]) # get all directories \n",
    "for folder in folders:\n",
    "    contents = os.listdir(os.path.join(train_path,folder)) # get list of contents\n",
    "    if len(contents) > mn: # if greater than the limit, print folder and number of contents\n",
    "        print(folder,len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(131, activation='softmax') # 131 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(1/255) # normalize the data\n",
    "test_datagen = ImageDataGenerator(1/255)\n",
    "# https://keras.io/api/preprocessing/image/\n",
    "# generate batches of tensor image data with real-time data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21952 images belonging to 131 classes.\n",
      "Found 20188 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # This is the source directory for training images  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "# flow_from_directory can be used if the directory is set up as train and test folders, \n",
    "# both folders have folders inside of images for each class\n",
    "# have to create a validation set\n",
    "# the tensorflow course on google used the validation set as a test set. that's really weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 - 112s - loss: 0.2253 - accuracy: 0.9440 - val_loss: 0.9972 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "100/100 - 110s - loss: 0.1901 - accuracy: 0.9440 - val_loss: 0.7189 - val_accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "100/100 - 109s - loss: 0.1733 - accuracy: 0.9500 - val_loss: 0.8644 - val_accuracy: 0.8210\n",
      "Epoch 4/10\n",
      "100/100 - 107s - loss: 0.1457 - accuracy: 0.9570 - val_loss: 1.1092 - val_accuracy: 0.8020\n",
      "Epoch 5/10\n",
      "100/100 - 113s - loss: 0.2047 - accuracy: 0.9460 - val_loss: 1.0121 - val_accuracy: 0.7750\n",
      "Epoch 6/10\n",
      "100/100 - 104s - loss: 0.1986 - accuracy: 0.9408 - val_loss: 0.9248 - val_accuracy: 0.8120\n",
      "Epoch 7/10\n",
      "100/100 - 109s - loss: 0.1361 - accuracy: 0.9580 - val_loss: 1.2288 - val_accuracy: 0.7360\n",
      "Epoch 8/10\n",
      "100/100 - 111s - loss: 0.2372 - accuracy: 0.9330 - val_loss: 1.4063 - val_accuracy: 0.7240\n",
      "Epoch 9/10\n",
      "100/100 - 110s - loss: 0.2450 - accuracy: 0.9375 - val_loss: 1.0345 - val_accuracy: 0.7890\n",
      "Epoch 10/10\n",
      "100/100 - 113s - loss: 0.0925 - accuracy: 0.9730 - val_loss: 0.7103 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)\n",
    "\n",
    "# overfits to the training set, tests badly on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The pgf.debug rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/elenabukreeva/miniconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9f7A8dfb2PedLEWSLQwmFSqhS6WFUqRlqCQpbtuVFn5KpZR0VaJo06XVbdMiyS0VkyVMyJZlkKwj2yyf3x/vM+PMmOXMmDPfc868n4/HecxZvsv7fM+Z9/l8P9tXnHMYY4yJXMW8DsAYY0xwWaI3xpgIZ4neGGMinCV6Y4yJcJbojTEmwlmiN8aYCGeJvggSkTkicnNBL+slEdkkIt2CsF0nImf47k8WkUcCWTYf++kvIl/lN05jciLWjz48iMhBv4dlgaNAiu/x7c65GYUfVegQkU3Arc65uQW8XQc0ds6tK6hlRaQBsBEo4ZxLLog4jclJca8DMIFxzpVPu59TUhOR4pY8TKiw72NosKqbMCcinUVkq4j8S0R2ANNFpIqIfCoiu0Rkr+9+Pb915ovIrb77sSLyvYiM9y27UUQuyeeyDUVkgYgkishcEXlRRN7OJu5AYnxMRH7wbe8rEanu9/qNIvKHiOwWkYdyOD7nisgOEYnye66XiPzqu99eRH4UkX0isl1EJolIyWy29bqIPO73+H7fOgkiMjDTspeJyFIROSAiW0RktN/LC3x/94nIQRE5L+3Y+q3fQUQWi8h+398OgR6bPB7nqiIy3fce9orIbL/XrhSRZb73sF5Eeviez1BNJiKj0z5nEWngq8K6RUQ2A/N8z7/n+xz2+74jLfzWLyMiz/o+z/2+71gZEflMRO7K9H5+FZGrsnqvJnuW6CNDbaAqcBowCP1cp/senwocBiblsP45wBqgOvA08JqISD6WfQdYBFQDRgM35rDPQGK8HhgA1ARKAvcBiEhz4GXf9uv49lePLDjnfgL+Brpk2u47vvspwD997+c8oCswJIe48cXQwxfPxUBjIHP7wN/ATUBl4DLgDr8EdYHvb2XnXHnn3I+Ztl0V+Ax4wffengM+E5Fqmd7DCccmC7kd57fQqsAWvm1N8MXQHngTuN/3Hi4ANmV3PLJwIdAM6O57PAc9TjWBJYB/VeN4oB3QAf0ePwCkAm8AN6QtJCKtgbrA53mIwwA45+wWZjf0H66b735n4BhQOoflo4G9fo/no1U/ALHAOr/XygIOqJ2XZdEkkgyU9Xv9beDtAN9TVjE+7Pd4CPCF7/6jwEy/18r5jkG3bLb9ODDNd78CmoRPy2bZ4cBHfo8dcIbv/uvA477704Cn/JY703/ZLLb7PDDBd7+Bb9nifq/HAt/77t8ILMq0/o9AbG7HJi/HGTgFTahVsljulbR4c/r++R6PTvuc/d7b6TnEUNm3TCX0h+gw0DqL5UoBe9B2D9AfhJcK+/8tEm5Woo8Mu5xzR9IeiEhZEXnFdyp8AK0qqOxffZHJjrQ7zrlDvrvl87hsHWCP33MAW7ILOMAYd/jdP+QXUx3/bTvn/gZ2Z7cvtPTeW0RKAb2BJc65P3xxnOmrztjhi+MJtHSfmwwxAH9ken/niMi3viqT/cDgALebtu0/Mj33B1qaTZPdsckgl+NcH/3M9maxan1gfYDxZiX92IhIlIg85av+OcDxM4PqvlvprPblnDsKvAvcICLFgH7oGYjJI0v0kSFz16l7gSbAOc65ihyvKsiuOqYgbAeqikhZv+fq57D8ycS43X/bvn1Wy25h51w8migvIWO1DWgV0Gq01FgRGJmfGNAzGn/vAB8D9Z1zlYDJftvNratbAlrV4u9UYFsAcWWW03Hegn5mlbNYbwvQKJtt/o2ezaWpncUy/u/xeuBKtHqrElrqT4vhL+BIDvt6A+iPVqkdcpmquUxgLNFHpgro6fA+X33vqGDv0FdCjgNGi0hJETkPuDxIMb4P9BSRTr6G0zHk/l1+B7gbTXTvZYrjAHBQRJoCdwQYw7tArIg09/3QZI6/AlpaPuKr777e77VdaJXJ6dls+3PgTBG5XkSKi8h1QHPg0wBjyxxHlsfZObcdrTt/yddoW0JE0n4IXgMGiEhXESkmInV9xwdgGdDXt3wMcE0AMRxFz7rKomdNaTGkotVgz4lIHV/p/zzf2Re+xJ4KPIuV5vPNEn1keh4og5aWfgK+KKT99kcbNHej9eKz0H/wrOQ7RufcKuBONHlvB/YCW3NZ7T9oe8Y859xffs/fhybhRGCqL+ZAYpjjew/zgHW+v/6GAGNEJBFtU3jXb91DwFjgB9HePudm2vZuoCdaGt+NNk72zBR3oHI7zjcCSehZzZ9oGwXOuUVoY+8EYD/wHcfPMh5BS+B7gf8j4xlSVt5Ez6i2AfG+OPzdB6wAFqN18uPImJveBFqibT4mH2zAlAkaEZkFrHbOBf2MwkQuEbkJGOSc6+R1LOHKSvSmwIjI2SLSyHeq3wOtl52d23rGZMdXLTYEmOJ1LOHMEr0pSLXRrn8H0T7gdzjnlnoakQlbItIdbc/YSe7VQyYHVnVjjDERzkr0xhgT4UJyUrPq1au7Bg0aeB2GMcaEjV9++eUv51yNrF4LyUTfoEED4uLivA7DGGPChohkHk2dzqpujDEmwlmiN8aYCGeJ3hhjIpwlemOMiXCW6I0xJsJZojfGmAhnid4YYyKcJXpjjAkFP/0EzzwTlE1bojfGGK/NmAGdO8Mrr8DBgwW+eUv0xhjjldRUeOghuOEGOPdc+PlnKJ/d5ZrzLySnQDDGmIh38CDcdBN89BHcdhtMmgQlSwZlV5bojTGmsG3eDFdcAStWwPPPw913gwRyTfr8sURvjDGF6ccfoVcvOHwYPvsMevQI+i6tjt4YYwrLjBlw0UVQrpz2simEJA+W6I0xJvgyN7ouWgTNmhXa7q3qxhhjgqkQG12zY4neGGOCpZAbXbNjid4YY4LBg0bX7FgdvTHGFDSPGl2zY4nemKJmxQoYPRq+/dbrSCKPx42u2bGqG1Ow/v4bVq+G+PjjtwMH4PzzoUsX/fKXLu11lEXP4cPw/vsweTIsXHj8+T59YPx4OPVU72KLFCHQ6Jodcc55HcMJYmJiXFxcnNdhmJwcOAC//ZYxocfHw6ZNx5cpUQLOPFMT+9KlWtopXRo6doSuXTXxt2sHxa28ETSrV8OUKfD667B3r34et98O114L06fDk0/qciNGwP33Q5kynoYbtvwbXZ97zpNGVxH5xTkXk+VrluhNjvbuzZjQV63Sv1u3Hl+mVClo2hSaN894a9RIkz3A/v2wYAHMm6e3X3/V5ytUgAsv1KTfpQu0bAnFrEbxpBw7pqXKyZNh/nz9DHr31gTfuXPGBLR5syb4d9+FBg00SV11lSc9Q8KWf6PrrFme1cefdKIXkR7ARCAKeNU591Sm16sA04BGwBFgoHNupe+1TUAikAIkZxeIP0v0HvjrrxNL5/HxsH378WXKltX6xswJvWFDiIrK2/527dIklJb4167V56tV00asLl201N+4sSWdQG3YoKX3adP0+DZsCIMGwYABUKtWzut++62WQleuhG7dYOJE/WxNzmbMgFtugbp14dNPPa2PP6lELyJRwFrgYmArsBjo55yL91vmGeCgc+7/RKQp8KJzrqvvtU1AjHPur0ADtkQfJM7Bzp1ZJ/Rdu44vV6HCicm8eXOtxw1WaXvrVk0233yjiX/LFn2+bt3jpf0uXawuObOkJPjkE53H/Kuv9Af3iiu09H7xxXn7vJKT9SzgkUcgMRHuuksbbStVClr4YSs1VY/TE0/oGekHH2ghxUMnm+jPA0Y757r7Hj8I4Jx70m+Zz4AnnXPf+x6vBzo453ZaovdASoomyrVrj1e7pFW57N17fLnKlbNO6PXqeVuKdg7Wrz9e2p837/gPUaNGx5P+RRflXlKNVJs3w9Sp8NpretZVr542AKaVLk/Grl3w8MO6/Ro1tB4/Ntaq1NKEaKPrySb6a4AezrlbfY9vBM5xzg31W+YJoLRz7h4RaQ8s9C3zi4hsBPYCDnjFOTclt4At0QcgKQn++APWrTvxtmGDvp6mWjVo0eLEhF67dnhUizinP1RpSX/+fK3zBzjrrOOJ/8IL9ccrUqWkwJw5Wnr//HM9LpdcAoMH69+CbtReskRL9QsXwtlnw7//DeecU7D7CDch0OianZNN9H2A7pkSfXvn3F1+y1RE6/DbACuApsCtzrnlIlLHOZcgIjWBr4G7nHMLstjPIGAQwKmnntrujz/+yMdbjTBHj2ovlnXr4PffMybzTZv0Hz9N+fJwxhkn3po311JZJElJ0SSUlvj/9z9tCCtWDNq2PZ74O3XSASvhLiFBS+5Tp+qZWu3aWnK/7TY47bTg7ts5eOcdbbDdvl1L9k8+qTEUNSHS6JqdoFfdZFpegI1AK+fcgUyvjUbr8sfntM8iVaI/fFhL4FmVzDdv1rrANBUrauNkWhL3v1+zZsiULArd0aM6MCUt8f/4o57RlCih/fbTEv/ZZ4dP98HUVJg7V0vv//2v/rhdfLHWvV9xxfHeTIUlMRHGjtVSbOnSMGqUlvZDoMqiUIRQo2t2TjbRF0cbY7sC29DG2Oudc6v8lqkMHHLOHROR24DznXM3iUg5oJhzLtF3/2tgjHPui5z2GXGJ/uBBrXPOKpn7d1MErWbJqmR+xhn6WlFN5nlx6BD88MPxxB8Xd/wHs3ZtLQU3aJD1X6/PAP78U/u3T5miBYDq1bXXzKBB+h3w2u+/w/DhWnXUpIn2zune3euogicEG12zUxDdKy8Fnke7V05zzo0VkcEAzrnJvlL/m2gXynjgFufcXhE5HfjIt5niwDvOubG57S/fiX7cuIx1015JTtbSeFp1y44dGV+vWTNjAk8rmTdqBFWqeBNzJNu/H777Tvvub9qkbRubNulndOxYxmWrV9eEn92PQTB6oDin8U2eDB9+qN/hCy/U0nvv3jpOIdR89pkm/HXr4MortaR/+uleR1WwQrTRNTtFZ8BUuXJamgsFdepkXSpv1EirYIz3UlP1Rzgt8fv/Tbt/+HDGdSpVyv5s4LTT8nbWtWcPvPGGVs+sWaMNybGxWnoPwaqBExw9qlPvPvaYFm7uuw8efND7s6KC4N/o+uyzMGxYyJ9NF51En5xc8MHkh0jeBxCZ0OOcDiTL/CPg/zcxMeM65crlXDVUs6bOZjh5so5GPXoUzjvv+LQE4dKG4C8hAf71L3j7be3mOX68vpcQT4zZ8m90nTlTezSFgaKT6I0pTM7Bvn0nngX4/92zJ+M6JUpo1UyFCjrD4e23Q+vWHgQfBD/8oA20S5fCBRfACy+E33sLg0bX7FiiN8YriYknVgk1bgz9+mmX2EiTkqJdQUeO1MF5gwdr1U7Vql5HlrMwanTNjiV6Y0zh2rNHu2C+9JK2PYwdqw2aoVSlefgwbNumt4kTw6bRNTuW6I0x3vj1V23InD8foqN1dG2nTsHdZ1rbSloSz+7mX61WrFjYNLpmJ6dEbxOBG2OCp1UrHcvw/vtw7716AZrrr4enn87fnDxHjmjjb04JPCHhxG6zIjovUt26Oqtnp056P+3WpElET5hnJXpjTOH4+28d6/L00zovz0MPwT336DgB57SEnVMC37oVdu8+cbtly2ZM2lndatcu/NHEhcyqbowxoWPjRk3ws2freJPSpbUUfuRIxuVEtDtqbkm8UqWwrW4pSFZ1Y4wJHQ0basPn119rnX358seTdr16x++fckrEl8ILiyV6Y4w3Lr5Ybybo7EoCxhgT4SzRG2NMhLNEb4wxEc4SvTHGRDhL9MYYE+Es0RtjTISzRG+MMRHOEr0xxkQ4S/TGGBPhLNEbY0yEs0RvjDERzhK9McZEOEv0xhgT4SzRG2NMhLNEb4wxEc4SvTHGRDhL9MYYE+Es0RtjTISzRG+MMRHOEr0xxkQ4S/TGGBPhAkr0ItJDRNaIyDoRGZHF61VE5CMR+VVEFonIWYGua4wxJrhyTfQiEgW8CFwCNAf6iUjzTIuNBJY551oBNwET87CuMcaYIAqkRN8eWOec2+CcOwbMBK7MtExz4BsA59xqoIGI1ApwXWOMMUEUSKKvC2zxe7zV95y/5UBvABFpD5wG1AtwXXzrDRKROBGJ27VrV2DRG2OMyVUgiV6yeM5levwUUEVElgF3AUuB5ADX1Sedm+Kci3HOxdSoUSOAsIwxxgSieADLbAXq+z2uByT4L+CcOwAMABARATb6bmVzW9cYY0xwBVKiXww0FpGGIlIS6At87L+AiFT2vQZwK7DAl/xzXdcYY0xw5Vqid84li8hQ4EsgCpjmnFslIoN9r08GmgFvikgKEA/cktO6wXkrxhhjsiLOZVll7qmYmBgXFxfndRjGGBM2ROQX51xMVq/ZyFhjjIlwluiNMSbCWaI3xpgIZ4neGGMinCV6Y4yJcJbojTEmwlmiN8aYCGeJ3hhjIpwlemOMiXCW6I0xJsJZojfGmAhnid4YYyKcJXpjjIlwluiNMSbCWaI3xpgIZ4neGGMinCV6Y4yJcJbojTEmwlmiN8aYCGeJ3hhjIpwlemOMiXCW6I0xJsJZojfGmAhnid4YYyKcJXpjjAkBqangXHC2bYneGGNCwIQJ0KMH/P13wW/bEr0xxnhs2zYYPRpKloRy5Qp++5bojTHGY/fdB0lJMHFicLZvid4YYzz07bcwcyaMGAGnnx6cfViiN8YYjyQlwdCh0LAh/OtfwdtP8eBt2hhjTE5eeAHi4+Hjj6FMmeDtJ6ASvYj0EJE1IrJOREZk8XolEflERJaLyCoRGeD32iYRWSEiy0QkriCDN8aYcJXWANuzJ1x+eXD3lWuJXkSigBeBi4GtwGIR+dg5F++32J1AvHPuchGpAawRkRnOuWO+1y9yzv1V0MEbY0y4CnYDrL9ASvTtgXXOuQ2+xD0TuDLTMg6oICIClAf2AMkFGmmY2LIFOneGl17SARDGGJNZYTTA+gsk0dcFtvg93up7zt8koBmQAKwAhjnn0tKcA74SkV9EZFB2OxGRQSISJyJxu3btCvgNhJKkJOjbFxYsgDvvhO7dNfEbY0yawmqA9RdIopcsnss8ULc7sAyoA0QDk0Skou+1js65tsAlwJ0ickFWO3HOTXHOxTjnYmrUqBFY9CHmkUdg4UKYMQMmT4Yff4SzzoI33gje0GZjTHhJa4CdODG4DbD+Akn0W4H6fo/roSV3fwOAD51aB2wEmgI45xJ8f/8EPkKrgiLOnDkwbhzcfjv066d/f/0VWreG2Fi46irYscPrKI0xXirMBlh/gST6xUBjEWkoIiWBvsDHmZbZDHQFEJFaQBNgg4iUE5EKvufLAf8AVhZU8KFi61a46SZo1Urnq0hz+ulaF/fss/Dll1q6f/997+I0xnirMBtg/eWa6J1zycBQ4EvgN+Bd59wqERksIoN9iz0GdBCRFcA3wL98vWxqAd+LyHJgEfCZc+6LYLwRryQnawn+8GF4990TT8WiouCee2DpUq2T69MHrr8e9uzxJl5jjDcKuwHWn7gQrDyOiYlxcXHh0eX+oYfgiSfg7behf/+cl01KgqeegjFjoEYNePVVuPTSwonTGOOdpCSIjtYC4apVwambF5FfnHMxWb1mUyCchC+/hCefhFtvzT3JA5QooQ22ixZBtWpw2WVw221w4EDwYzXGeMeLBlh/lujzKSEBbrwRWrTIe31bmzYQF6ddq6ZN07r9b78NTpzGGG951QDrzxJ9PiQnaz37oUPw3ntQtmzet1GqlFbj/O9/WtLv0gWGDdNtGmMih1cNsP4s0efDmDHw3Xfw8svQtOnJbatDB1i2DO66S0/v2rSBn34qmDiNMd7ysgHWnyX6PJo7Fx5/HAYM0KqbglCunCb5b76BI0egY0cYORKOHi2Y7RtjCp8XI2CzY4k+D7Zv10bX5s1h0qSC336XLjrIKjZWG3nbt4flywt+P8aY4PO6AdafJfoApaRokj94UPvL56dePhCVKsFrr8Enn8Cff8LZZ8PYsdouYIwJDwkJ3jfA+rNEH6DHHtP6thdf1BJ9sPXsCStXQu/e8PDDWpe/enXw92uMOXmh0ADrzxJ9AObN0wbYm2/WapXCUq2aNuTMnAnr12tD7fPP2/THxoSyb7+F//zH+wZYfzYyNhc7duiItqpVYfFibTj1Ko7bboNPP4ULL4Tp07WRxxgTOgpjBGx2bGRsPqWkwA036MjVd9/1LskD1K6t15WcNg2WLNFBVlOn2vTHxoSSUGqA9WeJPgdPPKFdHv/9b5150msi2q1zxQrtkTNokM6Vs22b15EZY0KtAdafJfpszJ+vH9oNN8DAgV5Hk9Fpp8HXX+sP0Hff6Y/QjBlWujfGS6HWAOvPEn0W/vxTpzho3FhHv0pW19jyWLFiOhhj+XJo1kx/kPr0gTC9CqMxYS0UG2D9WaLPJDVVR7zu3av18uXLex1Rzho31vlyxo3TvvctWsDs2V5HZUzREUojYLNjiT6Tp56Cr77SRpVWrbyOJjBRUfDAA/DLL1CvHvTqpV1B9+3zOjJjIl+oNsD6s0TvZ8ECnS++Xz+dYz7cnHWWToj26KNaZ582hXJioteRGROZQrkB1p8lep9duzTBN2oEr7wSmvXygShZEv7v/zThN2wIw4drKf/++2HzZq+jMyayhHIDrD9L9Gi9/E03we7dWi9foYLXEZ28mBj4/ntN+JdcohctP/10bWQOkbFoxoS1UG+A9WeJHnj6afjiC51eIDra62gK1jnnHJ9CYfhw+OwznSjtggu00TYlxesIjQk/4dAA66/IJ/rvv9dJw669Fm6/3etogue002D8eNiyRUv3mzdro22TJjrl8t9/ex2hMeEjHBpg/RXpuW7++ksnCitVSqcVqFgx6LsMGcnJ8NFH8Oyz8PPPUKWK/tANHQp163odnTGhKyFBC0idO2uX5lBhc91kITVVuyD++ade97UoJXmA4sV1gNVPP8HChdC1q1ZhNWig4wiWLvU6QmNCU7g0wPorson+2Wfh88/huee0VF+UnXee/titWwd33ql1923bwkUX6WyZNi1ywUhK0q54oVQKNHkTTg2w/opk1c3ChdoY2auX9rIJ166UwbJvH7z6qpZYtm6FM8+Ef/5TeyYF68pake7AAbjmGp2jqEoV/VGtWtXrqExeeDkFcSCs6sbP7t3Qt682Tr76qiX5rFSurKenGzZo6aViRbjjDqhfXxuut2/3OsLwsmULdOqkF7AZOVJ/SB9/3OuoTF6FWwNsBs65kLu1a9fOBUNqqnOXX+5ciRLOLV4clF1EpNRU5xYscO6qq5wTca5kSediY51bvtzryELf0qXO1anjXIUKzn35pT53yy36Hfz9d29jM4Hbts258uWd69nT60iyB8S5bHJqkSrRT5ig9aPPPqsDikxgROD887WXztq1Og/+u+9C69Zw8cUwZ47V42dlzhw9bsWKwQ8/wD/+oc8/9piOYA6H/tdGhWMDbAbZ/QJ4eQtGif7HH50rXty53r21hGpOzu7dzj35pJZWwblmzZybOtW5Q4e8jiw0vPKKc1FRzkVHa2kwszFj9LgtWFD4sZm8mTdPP6tRo7yOJGfkUKIvEo2xe/dqzxoR7TZYuXKBbbrIO3ZMS/fPPgvLlkGNGjBkiN5q1vQ6usKXmqr18OPG6dQTs2ZlPaXGoUPayH3KKTqOoViROrcOH6HeAOvvpBtjRaSHiKwRkXUiMiKL1yuJyCcislxEVonIgEDXDTbn9PJ7CQn6T2dJvmCVLKkXPVmyRLuenXuuTqp26qk6A+iqVV5HWHiOHNG5hMaN08FnH3+c/bxJZcvqpSrj4rTB24SmsG6A9ZddUT/tBkQB64HTgZLAcqB5pmVGAuN892sAe3zL5rpuVreCrLqZMEFPuyZMKLBNmlysXu3c4MHOlSmjx/6yyyK/4fGvv5zr2FHf77hxgVUPpqQ417atc/XrW5VXKAqHBlh/nGRjbHtgnXNug3PuGDATuDLz7wVQQUQEKO9L9MkBrhs0ixfrBTmuvBKGDSusvZomTfQSjJs3a8Pj//4HLVvqRV2SkryOruCtW6eDzuLi9KzxgQcC67ZbrJhWeaXNP2RCS9g3wPoJJNHXBbb4Pd7qe87fJKAZkACsAIY551IDXDco9u3Ticrq1IFp06y/vBeqV9d+9/HxcOml8OCD2ttp0SKvIys4P/6oSX73bpg7V79zedG5sxZEnnwSduwISogmH8J1BGx2Akn0WaXIzC243YFlQB0gGpgkIhUDXFd3IjJIROJEJG7XSV7h2jkYOFBHdc6aZSMQvVa3LnzwgXbP3L1b6/GHDQv/K1998AF06QKVKumcQZ065W87Tz+t9fujRhVsfCZ/wm0K4kAEkui3AvX9HtdDS+7+BgAf+qqK1gEbgaYBrguAc26Kcy7GORdTo0aNQOPP0qRJmlSeekrnYzeh4aqrtHQ/ZAj8+9/QvHl4zvvinFa59Omjvbl+/FEv0p5fZ56px+TVV2HlyoKL0+RPxDTA+suu8t4db2gtDmwAGnK8QbVFpmVeBkb77tcCtgHVA1k3q9vJNMYuXqwjNy+/3PrLh7KFC51r0UIbL/v0cS4hweuIApOU5NyQIRr3NdcUXCPqX385V7myc927F8z2TP6EWwOsP3JojA1oABNwKbAW7UHzkO+5wcBg3/06wFdo/fxK4Iac1s3tlt9Ev2+fc6efrr0Ydu/O1yZMITp61LnHH3euVCnnKlXSQUYpKV5Hlb3ERO1BBM7df3/Bx/rss7rtOXMKdrsmcP366fdx/XqvI8m7k070hX3LT6JPTdUSVlSUcz/8kOfVjYfWrHGuc2f9Nnbq5Fx8vNcRnSghQbtCFivm3IsvBmcfR44416iRnukkJQVnHyZ74TICNjs5JfqIGY+3dy+sXq29Fzp08DoakxdnnqkzO06bpgOsoqN10NXRo15Hplat0gbkNWt0ENSQIcHZT6lSOthq1So9FqbwRGIDrL+ISfRVq2q3vXvv9ToSkx8iOoJ59Wq4+mq9QEebNnpNXy99840WHI4dgwUL4LLLgru/3r21984jj+wONawAABeLSURBVOgc9qZwRGQDrJ+ISfSgH5DNGRLeataEd97Rq38dOqSzPw4erOMiCtsbb0CPHjoP/88/61W3gk1Er3r2559aujfBl5CgBYuePeHyy72OJjgsLZqQdMkl2tXwnntg6lRo1gzef1+7Ngabc/qPHxsLF16oUwyfemrw95vm7LOhf39N+Js3F95+iyLn9PKZycnw/PNeRxM8luhNyCpfXvurL1qkszz26aN98bdsyX3d/Dp2TC8a/3//p4n+8891QFRhe+IJ/TtyZOHvuyh57z29RvKYMdCokdfRBI8lehPy2rXTZP/MM3rN1ebNdcBVSkrB7mffPq2qeest/cefNk1n5/TCqafq2cyMGZE1ZUQo2bVLG2DPPluviRzJLNGbsFC8uE4ytWoVdOwId9+tjaS//low29+0Sbf7/ffw5pvaGOr1/EgjRmibxb33Fk6VVVEzbJj+uE+bpt+vSGaJ3oSVhg31En0zZsDGjVraHzlSLwyRX3Fx2n1y2zb48ku48caCi/dkVKigs39+/z18+KHX0USWjz/WScsefhjOOsvraIKvSFxhykSm3bu1lP/661q/+sor0LVr3rbxySfQt69eGevzz7VaKJQkJ+u4giNH9GymVCmvIwp/+/bp51yjhk5l7lX1XEE76StMGROKqlWD6dO1r7sIdOumDai7dwe2/osvauNu8+Y6+2SoJXnQKoVnn4X16zVec/LuvVe7r3rZBlPYLNGbsNeli9bVjxypVTpNm+rf7E5WU1P1n33oUO07PX8+1K5dqCHnSffuenvsscB/xEzWvvpKE/wDD2i1X1Fhid5EhDJlYOxY+OUXrca54Qbti79xY8blDh3SbprPPQd33aV13+XKeRNzXowfryNlx4zxOpLwlZgIgwZpQeDRR72OpnBZojcRpVUrHeD073/r3xYtNEkmJ+vpepcueq2CCRN0uHtUlNcRB+ass/Ri6y+9BGvXeh1NeHrwQR2A9tprULq019EULmuMNRFryxYd9fjJJzpvzv79Otx9xgydUybc7NwJZ5yhDc6zZ3sdTXhZsEBHOQ8fHrnX57XGWFMk1a8P//2vTp2wfbueus+fH55JHqBWLS2V/ve/+j5MYA4dgltu0Wu/Pv6419F4w0r0pkg4dEinovViOoOCdPgwNGlyvGugTeKXu/vu055L8+bBRRd5HU3wWIneFHlly4Z/kgdtdH7ySViyBN5+2+toQt/PP2tVze23R3aSz42V6I0JM6mpOpI3IUEbZsuW9Tqi0HT0qE4tfeCADjarWNHriILLSvTGRJBixbR76LZtWiVhsvb443oxkSlTIj/J58YSvTFhqFMnvRLXuHHa0GwyWrZMq7huvlnHUxR1luiNCVPjxun8+Y884nUkoSUpCQYOhOrV9czHWKI3Jmw1aqSje6dNg+XLvY4mdDzzDCxdCi+/rNeSNpbojQlrDz8MVapoF8IQ7FdR6OLj9epg114LvXp5HU3osERvTBirUgVGjYK5c3We/qIsJUWrbCpU0CkwzHGW6I0Jc4MHQ+PGWqpPTvY6Gu+88IL2m3/hBb0ylznOEr0xYa5kSXj6afjtN5g61etovLFuHTz0EFx+OfTr53U0occSvTER4MorddKuRx/VyduKktRUndmzZEltgPX6Wr+hKGwuiZuUlMTWrVs5cuSI16GYEFC6dGnq1atHiRIlvA4lJIjo4KmYGO0//tRTXkdUeF55Bb77TqcfrlvX62hCU9hMgbBx40YqVKhAtWrVEPvJLtKcc+zevZvExEQaNmzodTgh5eabYeZMWLMGGjTwOprg++MPnav/vPP0wu5FOTVExBQIR44csSRvABARqlWrZmd3WRg7Vi+m8uCDXkcSfM7pZGXO6TQHlhqyFzaJHrAkb9LZdyFr9epp75uZM/WC55HsjTe0FD9uXNE4ezkZASV6EekhImtEZJ2IjMji9ftFZJnvtlJEUkSkqu+1TSKywveaTUlpTJA98IBe7PyeeyJ3EFVCAvzzn3D++XDHHV5HE/pyTfQiEgW8CFwCNAf6iUhz/2Wcc88456Kdc9HAg8B3zrk9fotc5Hs9y/qjULd7926io6OJjo6mdu3a1K1bN/3xsWPHclw3Li6Ou+++O9d9dOjQoaDCNUVc+fI6c+OPP8J773kdTcFzDoYMgSNHtAHWLr6Su0B63bQH1jnnNgCIyEzgSiA+m+X7Af8pmPBCQ7Vq1Vi2bBkAo0ePpnz58tx3333prycnJ1O8eNaHMiYmhpiY3H/fFi5cWDDBFqKUlBSiwuXq2kVMbKwOHBoxAq64IrIuhv3uu3o5xWee0YFiJneBJPq6wBa/x1uBc7JaUETKAj2AoX5PO+ArEXHAK865KdmsOwgYBHDqqafmHNHw4ToPaUGKjobnnw948djYWKpWrcrSpUtp27Yt1113HcOHD+fw4cOUKVOG6dOn06RJE+bPn8/48eP59NNPGT16NJs3b2bDhg1s3ryZ4cOHp5f2y5cvz8GDB5k/fz6jR4+mevXqrFy5knbt2vH2228jInz++efcc889VK9enbZt27JhwwY+/fTTDHFt2rSJG2+8kb///huASZMmpZ8tPP3007z11lsUK1aMSy65hKeeeop169YxePBgdu3aRVRUFO+99x5btmxJjxlg6NChxMTEEBsbS4MGDRg4cCBfffUVQ4cOJTExkSlTpnDs2DHOOOMM3nrrLcqWLcvOnTsZPHgwGzZsAODll19mzpw5VK9enWHDhgHw0EMPUatWrYDOeEzeREVpd8uLL9bpAO6/3+uICsauXTB0KLRvr1U3JjCBJPqsWr2yq/m7HPghU7VNR+dcgojUBL4WkdXOuQUnbFB/AKaAdq8MIC7PrV27lrlz5xIVFcWBAwdYsGABxYsXZ+7cuYwcOZIPPvjghHVWr17Nt99+S2JiIk2aNOGOO+44oS/40qVLWbVqFXXq1KFjx4788MMPxMTEcPvtt7NgwQIaNmxIv2yG/9WsWZOvv/6a0qVL8/vvv9OvXz/i4uKYM2cOs2fP5ueff6Zs2bLs2aMfUf/+/RkxYgS9evXiyJEjpKamsmXLliy3naZ06dJ8//33gFZr3XbbbQA8/PDDvPbaa9x1113cfffdXHjhhXz00UekpKRw8OBB6tSpQ+/evRk2bBipqanMnDmTRYsW5fm4m8B06waXXqrVOLGxep3ZcHf33TogbNo0/TEzgQkk0W8F6vs9rgckZLNsXzJV2zjnEnx//xSRj9CqoBMSfZ7koeQdTH369Emvuti/fz8333wzv//+OyJCUlJSlutcdtlllCpVilKlSlGzZk127txJvXr1MizTvn379Oeio6PZtGkT5cuX5/TTT0/vN96vXz+mTDnx5CgpKYmhQ4eybNkyoqKiWLt2LQBz585lwIABlPVdd65q1aokJiaybds2evmm+Ssd4Pn9ddddl35/5cqVPPzww+zbt4+DBw/SvXt3AObNm8ebb74JQFRUFJUqVaJSpUpUq1aNpUuXsnPnTtq0aUO1atUC2qfJn2eegVatdEbHSZO8jubkzJ6tvYkeewxatPA6mvASSDPGYqCxiDQUkZJoMv8480IiUgm4EPiv33PlRKRC2n3gH8DKggg8FJQrVy79/iOPPMJFF13EypUr+eSTT7Lt412qVKn0+1FRUSRnMQtVVssEOrBtwoQJ1KpVi+XLlxMXF5feWOycO6FLYnbbLF68OKmpqemPM78X//cdGxvLpEmTWLFiBaNGjcq1b/utt97K66+/zvTp0xk4cGBA78nkX/PmMGgQTJ4Mq1d7HU3+7d2rvWtat4Z//cvraMJProneOZeM1rl/CfwGvOucWyUig0VksN+ivYCvnHN/+z1XC/heRJYDi4DPnHNfFFz4oWP//v3U9Y2/fv311wt8+02bNmXDhg1s2rQJgFmzZmUbxymnnEKxYsV46623SElJAeAf//gH06ZN49ChQwDs2bOHihUrUq9ePWbPng3A0aNHOXToEKeddhrx8fEcPXqU/fv3880332QbV2JiIqeccgpJSUnMmDEj/fmuXbvy8ssvA9poe+DAAQB69erFF198weLFi9NL/ya4Ro+GcuW022W4uvderZ+fNg1s1ou8C6hjknPuc+fcmc65Rs65sb7nJjvnJvst87pzrm+m9TY451r7bi3S1o1EDzzwAA8++CAdO3ZMT64FqUyZMrz00kv06NGDTp06UatWLSpVqnTCckOGDOGNN97g3HPPZe3ateml7x49enDFFVcQExNDdHQ048ePB+Ctt97ihRdeoFWrVnTo0IEdO3ZQv359rr32Wlq1akX//v1p06ZNtnE99thjnHPOOVx88cU0bdo0/fmJEyfy7bff0rJlS9q1a8eqVasAKFmyJBdddBHXXnut9dgpJDVrwsiR8MknMG+e19Hk3ZdfwvTpWpJv29braMJT2Mx189tvv9GsWTOPIgoNBw8epHz58jjnuPPOO2ncuDH/DLOuB6mpqbRt25b33nuPxifZN86+E4E7cgSaNtULlcTFhU9D5oEDOpdN+fKwZElkdRMtaBEx142BqVOnEh0dTYsWLdi/fz+333671yHlSXx8PGeccQZdu3Y96SRv8qZ0aZ3Rctky8LWRh4URI2DrVh0YZUk+/6xEb8KWfSfyxjno0EFnfPz9d623D2XffQedO2t/+eee8zqa0GclemNM+pz127drt8tQdugQ3HILNGqk4wDMybFEb0wR0qEDXHutJvolS0J30rNHHoH16+HVV8E39MOcBEv0xhQxTz2lpft27eC007Sf/Ycfhs4lCH/6CSZM0H7znTt7HU1ksERvTBHTsCGsXasX6zj7bJg1C66+GqpX1+vOPvkkLF2q12ItbEePwsCBOq9+UbocYrBZog9Q586d+fLLLzM89/zzzzNkyJAc10lrVL700kvZt2/fCcuMHj06vU97dmbPnk18/PHJQh999FHmzp2bl/CNyaBOHbjtNvjgA/jrL1iwQAdUHTyofe7bttVlbr4Z/vMfXaYwPPYY/Pab/ghVrFg4+ywKLNEHqF+/fsycOTPDczNnzsx2crHMPv/8cypXrpyvfWdO9GPGjKFbt2752pZXgjGIzBSMEiX0Ah5jx8Ivv8COHdoFs2tX+OwzuP56HXR1zjkwapTOcx+Mj3PpUi3Fx8ZCjx4Fv/2iLCwT/fDhWndXkLfhw3Pe5zXXXMOnn37K0aNHAZ0OOCEhgU6dOnHHHXcQExNDixYtGDVqVJbrN2jQgL98xaKxY8fSpEkTunXrxpo1a9KXmTp1KmeffTatW7fm6quv5tChQyxcuJCPP/6Y+++/n+joaNavX09sbCzvv/8+AN988w1t2rShZcuWDBw4MD2+Bg0aMGrUKNq2bUvLli1ZncVEJ5s2beL888+nbdu2tG3bNsOc+E8//TQtW7akdevWjBihFxVbt24d3bp1o3Xr1rRt25b169czf/58evbsmb7e0KFD06eAaNCgAWPGjKFTp0689957Wb4/gJ07d9KrVy9at25N69atWbhwIY888ggTJ05M3+5DDz3ECy+8kPOHZApErVpw440wYwbs3Ak//6zTKERFaQ+YDh10Jsy+feH117UXz8lKSoIBA3S71pWy4IVlovdCtWrVaN++PV98oVP1zJw5k+uuuw4RYezYscTFxfHrr7/y3Xff8euvv2a7nV9++YWZM2eydOlSPvzwQxYvXpz+Wu/evVm8eDHLly+nWbNmvPbaa3To0IErrriCZ555hmXLltGoUaP05Y8cOUJsbCyzZs1ixYoVJCcnp88vA1C9enWWLFnCHXfckWX1UNqUxkuWLGHWrFnp88L7T2m8fPlyHvBNktK/f3/uvPNOli9fzsKFCznllFNyPW5pUxr37ds3y/cHpE9pvHz5cpYsWUKLFi245ZZbeOONNwDSpzTu379/rvszBSsqSud+f/RRWLhQ55uZNQuuukqrewYM0Cqe6Ggd3DR/PuRy0bUsjRsHy5fDyy/r6F1TsAKZpjjkeDVLcVr1zZVXXsnMmTOZNm0aAO+++y5TpkwhOTmZ7du3Ex8fT6tWrbLcxv/+9z969eqVPl3wFVdckf5adlP+ZmfNmjU0bNiQM888E4Cbb76ZF198keG+05PevXsD0K5dOz788MMT1rcpjU1eVa2q3TOvvVa7Zq5YAV98obfnntOEXaGCVvv06AHdu+d+4e5Vq7Ru/rrr9AfEFLywTPReueqqq7jnnntYsmQJhw8fpm3btmzcuJHx48ezePFiqlSpQmxsbK5T9WaeLjhNbGwss2fPpnXr1rz++uvMnz8/x+3kNqo5bbrj7KZD9p/SODU1NT15B3NK47y8v7QpjXfs2GFTGocgEZ3rvlUrbchNTNRJ0774AubM0fnjQefY6dFDbxdcAGXKHN9GSor2sqlYUa+EZYLDqm7yoHz58nTu3JmBAwemN8IeOHCAcuXKUalSJXbu3MmcOXNy3MYFF1zARx99xOHDh0lMTOSTTz5Jfy27KX8rVKhAYmLiCdtq2rQpmzZtYt26dYDORHnhhRcG/H5sSmNTkCpUgCuv1OqXjRt1/vvnn9cS/eTJmuirVoVLLoGJE2HNGu0vv2iRJvlIuAJWqLJEn0f9+vVj+fLl9O2rMzK3bt2aNm3a0KJFCwYOHEjHjh1zXD/t+rLR0dFcffXVnH/++emvZTflb9++fXnmmWdo06YN69evT3++dOnSTJ8+nT59+tCyZUuKFSvG4MGDCZRNaWyCRQSaNIFhw7R0v2ePlvQHD9YfgeHDtaR///168XK/Gj4TBDapmQlZuU1pbN+J8LVxo84zv3SpXuawdm2vIwp/OU1qZnX0JiTFx8fTs2dPevXqZVMaR6CGDbV0bwqHJXoTkpo3b86GDRu8DsOYiBBWdfShWM1kvGHfBWMCFzaJvnTp0uzevdv+wQ3OOXbv3h1wX35jirqwqbqpV68eW7duZdeuXV6HYkJA6dKlqVevntdhGBMWwibRlyhRgoYNG3odhjHGhJ2wqboxxhiTP5bojTEmwlmiN8aYCBeSI2NFZBfwRz5Xrw4U0vVwQp4di4zseGRkx+O4SDgWpznnspwxKCQT/ckQkbjshgEXNXYsMrLjkZEdj+Mi/VhY1Y0xxkQ4S/TGGBPhIjHRT/E6gBBixyIjOx4Z2fE4LqKPRcTV0RtjjMkoEkv0xhhj/FiiN8aYCBcxiV5EeojIGhFZJyIjvI7HSyJSX0S+FZHfRGSViAzzOiaviUiUiCwVkU+9jsVrIlJZRN4XkdW+78h5XsfkJRH5p+//ZKWI/EdEIm5a1IhI9CISBbwIXAI0B/qJSHNvo/JUMnCvc64ZcC5wZxE/HgDDgN+8DiJETAS+cM41BVpThI+LiNQF7gZinHNnAVFAX2+jKngRkeiB9sA659wG59wxYCZwpccxecY5t905t8R3PxH9R67rbVTeEZF6wGXAq17H4jURqQhcALwG4Jw75pzb521UnisOlBGR4kBZIMHjeApcpCT6usAWv8dbKcKJzZ+INADaAD97G4mnngceAFK9DiQEnA7sAqb7qrJeFZFyXgflFefcNmA8sBnYDux3zn3lbVQFL1ISvWTxXJHvNyoi5YEPgOHOuQNex+MFEekJ/Omc+8XrWEJEcaAt8LJzrg3wN1Bk27REpAp69t8QqAOUE5EbvI2q4EVKot8K1Pd7XI8IPP3KCxEpgSb5Gc65D72Ox0MdgStEZBNapddFRN72NiRPbQW2OufSzvDeRxN/UdUN2Oic2+WcSwI+BDp4HFOBi5REvxhoLCINRaQk2pjysccxeUZEBK2D/c0595zX8XjJOfegc66ec64B+r2Y55yLuBJboJxzO4AtItLE91RXIN7DkLy2GThXRMr6/m+6EoGN02FzKcGcOOeSRWQo8CXaaj7NObfK47C81BG4EVghIst8z410zn3uYUwmdNwFzPAVijYAAzyOxzPOuZ9F5H1gCdpbbSkROB2CTYFgjDERLlKqbowxxmTDEr0xxkQ4S/TGGBPhLNEbY0yEs0RvjDERzhK9McZEOEv0xhgT4f4fK4b3zvBCZX8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-00d4178f12ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m \u001b[0;31m# resnet50 input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m inception_base = applications.ResNet50(weights=\"https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\",\n\u001b[0;32m----> 4\u001b[0;31m                                        include_top=False)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ValueError('The `weights` argument should be either '\n\u001b[0m\u001b[1;32m    197\u001b[0m                          \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                          \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications\n",
    "img_width, img_height = 224, 224 # resnet50 input\n",
    "inception_base = applications.ResNet50(weights=\"https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\",\n",
    "                                       include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                'releases/download/v0.2/'\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.2/'\n",
    "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-7cc2e8bad1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test/Apple Braeburn/3_100.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "history.predict(os.path(\"Test/Apple Braeburn/3_100.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to Physalis with a 2.05 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "\n",
    "img_height, img_width = 256, 256\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "#sunflower_path = os.path.abspath(\"fruits-360/Test/Cauliflower/9_100.jpg\")\n",
    "sunflower_path = os.path.abspath(\"fruits-360/mah_test/banana3.jpeg\")\n",
    "\n",
    "#sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "#sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    sunflower_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h5py' has no attribute 'File'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-1fa70971d278>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    319\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;31m# `add_loss.`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;31m# If file exists and should not be overwritten.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'h5py' has no attribute 'File'"
     ]
    }
   ],
   "source": [
    "saveResult = await model.save('downloads://my-model-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-3d04b83d3b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/model_json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muncompiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "model_loaded = tf.keras.models.model_from_json(\"~/model_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/\n",
    "# backing the model up every 2 hours while it's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

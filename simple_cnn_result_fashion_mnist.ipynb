{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_train_path = os.path.abspath(\"2243_9243_bundle_archive/fashion-mnist_train.csv\")\n",
    "notebook_test_path = os.path.abspath(\"2243_9243_bundle_archive/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "train_dataset = pandas.read_csv(notebook_train_path)\n",
    "test_dataset = pandas.read_csv(notebook_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(30, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(60, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2), \n",
    "  tf.keras.layers.Conv2D(120, (3,3), activation='relu'), \n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(), \n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_three.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_model_three = model_three.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=N_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.head())\n",
    "\n",
    "# Create a dictionary for each type of label \n",
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to normalize the values\n",
    "# need to convert to tensors\n",
    "# define the label column as target\n",
    "\n",
    "# convert the train_dataset to X_train and y_train\n",
    "\n",
    "# data preprocessing\n",
    "def data_preprocessing(raw):\n",
    "    out_y = keras.utils.to_categorical(raw.label) \n",
    "    # the label column is now categorical\n",
    "    # i.e. the target column\n",
    "    # 10 is the amount of categories. let's say the # will be inferred\n",
    "    x_as_array = raw.values[:,1:] # everything but the label col\n",
    "    x_shaped_array = x_as_array.reshape(raw.shape[0], 28, 28, 1) # reshaping to tensors\n",
    "    out_x = x_shaped_array / 255 # normalize the values\n",
    "    return out_x, out_y\n",
    "\n",
    "X_train, y_train = data_preprocessing(train_dataset)\n",
    "X_test, y_test = data_preprocessing(test_dataset)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=N_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_two.history.history\n",
    "# https://stackoverflow.com/questions/51731207/python-neural-network-typeerror-history-object-is-not-subscriptable\n",
    "print(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "\n",
    "    epochs = range(len(acc)) # Get number of epochs\n",
    "\n",
    "    #------------------------------------------------\n",
    "    # Plot training and validation accuracy per epoch\n",
    "    #------------------------------------------------\n",
    "    plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "    plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.figure()\n",
    "\n",
    "    #------------------------------------------------\n",
    "    # Plot training and validation loss per epoch\n",
    "    #------------------------------------------------\n",
    "    plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "    plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_three = model_three.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "plot_accuracy_and_loss(model_three)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
